{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import normalize\n",
    "\n",
    "x_train = normalize(x_train)\n",
    "x_test = normalize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0.0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.0,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.0,  # randomly shift images vertically (fraction of total height)\n",
    "        brightness_range=None,  \n",
    "        shear_range=0.0,  # set range for random shear\n",
    "        zoom_range=0.0,  # set range for random zoom\n",
    "        channel_shift_range=0.0,  # set range for random channel shifts\n",
    "        fill_mode='nearest',  # set mode for filling points outside the input boundaries\n",
    "        cval=0.0,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        rescale=None,  # set rescaling factor (applied before any other transformation)\n",
    "        preprocessing_function=None,  # set function that will be applied on each input\n",
    "        data_format=None,  # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        validation_split=0.0  # fraction of images reserved for validation (strictly between 0 and 1)\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import ZeroPadding2D, Conv2D, MaxPooling2D, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "#NAME = 'cifar10-8blocks-elu-lr-schedule-l2-regulizer-horizontal-flipping-{}'.format(datetime.datetime.now())\n",
    "NAME = 'cifar10-7blocks-my_activation-lr-schedule-l2-regulizer-horizontal-flipping-{}'.format(datetime.datetime.now())\n",
    "tensorboard = TensorBoard(log_dir='./logs/{}'.format(NAME),\n",
    "                          #histogram_freq=2,\n",
    "                          #write_graph=True,\n",
    "                          #write_grads=True,\n",
    "                          #write_images=True,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    if epoch < 70:\n",
    "        return 0.01\n",
    "    elif epoch < 170:\n",
    "        return 0.005\n",
    "    elif epoch < 270:\n",
    "        return 0.0005\n",
    "    else:\n",
    "        return 0.00005\n",
    "schedule = LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def my_activation(x):\n",
    "    return tf.where(x > 0.0,\n",
    "                    tf.log(tf.maximum(x, 0.0) + 1.0),\n",
    "                    -tf.log(-tf.minimum(x, 0.0) + 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #Block 1\n",
    "    ZeroPadding2D(input_shape=(32, 32, 3)),\n",
    "    Conv2D(384, 3, kernel_regularizer=l2(l=0.0005)), # 32\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(), # 16\n",
    "    # Block 2\n",
    "    Conv2D(384, 1, kernel_regularizer=l2(l=0.0005)), # 16\n",
    "    Activation('relu'),\n",
    "    ZeroPadding2D(),\n",
    "    Conv2D(384, 2, kernel_regularizer=l2(l=0.0005)), # 17\n",
    "    Activation('relu'),\n",
    "    ZeroPadding2D(),\n",
    "    Conv2D(640, 2, kernel_regularizer=l2(l=0.0005)), # 18\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(), # 9\n",
    "    Dropout(0.1),\n",
    "    # Block 3\n",
    "    Conv2D(640, 1, kernel_regularizer=l2(l=0.0005)), # 9\n",
    "    Activation('relu'),\n",
    "    ZeroPadding2D(),\n",
    "    Conv2D(768, 2, kernel_regularizer=l2(l=0.0005)), # 10\n",
    "    Activation('relu'),\n",
    "    ZeroPadding2D(),\n",
    "    Conv2D(768, 2, kernel_regularizer=l2(l=0.0005)), # 11\n",
    "    Activation('relu'),\n",
    "    ZeroPadding2D(),\n",
    "    Conv2D(768, 2, kernel_regularizer=l2(l=0.0005)), # 12\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(), # 6\n",
    "    Dropout(0.2),\n",
    "    # Block 4\n",
    "    Conv2D(768, 1, kernel_regularizer=l2(l=0.0005)), # 6\n",
    "    Activation('relu'),\n",
    "    ZeroPadding2D(),\n",
    "    Conv2D(896, 2, kernel_regularizer=l2(l=0.0005)), # 7\n",
    "    Activation('relu'),\n",
    "    ZeroPadding2D(),\n",
    "    Conv2D(896, 2, kernel_regularizer=l2(l=0.0005)), # 8\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(), # 4\n",
    "    Dropout(0.3),\n",
    "    # Block 5\n",
    "    Conv2D(896, 1, kernel_regularizer=l2(l=0.0005)), # 4\n",
    "    Activation('relu'),\n",
    "    ZeroPadding2D(),\n",
    "    Conv2D(1024, 2, kernel_regularizer=l2(l=0.0005)), # 5\n",
    "    Activation('relu'),\n",
    "    ZeroPadding2D(),\n",
    "    Conv2D(1024, 2, kernel_regularizer=l2(l=0.0005)), # 6\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(), # 3\n",
    "    Dropout(0.4),\n",
    "    # Block 6\n",
    "    Conv2D(1024, 1, kernel_regularizer=l2(l=0.0005)), # 3\n",
    "    Activation('relu'),\n",
    "    Conv2D(1152, 2, kernel_regularizer=l2(l=0.0005)), # 2\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(), # 1\n",
    "    Dropout(0.5),\n",
    "    # Block 7\n",
    "    Conv2D(1152, 1, kernel_regularizer=l2(l=0.0005)), # 1\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    # Block 8\n",
    "    Conv2D(10, 1, kernel_regularizer=l2(l=0.0005)), # 1\n",
    "    Activation('sigmoid'),\n",
    "    Flatten(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Block 1\n",
    "    ZeroPadding2D(padding=(4, 4), input_shape=(32, 32, 3)),\n",
    "    Conv2D(192, 5, kernel_regularizer=l2(l=0.0005)), # 36\n",
    "    Activation(my_activation),\n",
    "    MaxPooling2D(), # 18\n",
    "    # Block 2\n",
    "    Conv2D(192, 1, kernel_regularizer=l2(l=0.0005)), # 18\n",
    "    Activation(my_activation),\n",
    "    ZeroPadding2D(),\n",
    "    Conv2D(240, 3, kernel_regularizer=l2(l=0.0005)), # 18\n",
    "    Activation(my_activation),\n",
    "    MaxPooling2D(), # 9\n",
    "    Dropout(0.1),\n",
    "    # Block 3\n",
    "    Conv2D(240, 1, kernel_regularizer=l2(l=0.0005)), # 9\n",
    "    Activation(my_activation),\n",
    "    ZeroPadding2D(),\n",
    "    Conv2D(260, 2, kernel_regularizer=l2(l=0.0005)), # 10\n",
    "    Activation(my_activation),\n",
    "    MaxPooling2D(), # 5\n",
    "    Dropout(0.2),\n",
    "    # Block 4\n",
    "    Conv2D(260, 1, kernel_regularizer=l2(l=0.0005)), # 5\n",
    "    Activation(my_activation),\n",
    "    ZeroPadding2D(),\n",
    "    Conv2D(280, 2, kernel_regularizer=l2(l=0.0005)), # 6\n",
    "    Activation(my_activation),\n",
    "    MaxPooling2D(), # 3\n",
    "    Dropout(0.3),\n",
    "    # Block 5\n",
    "    Conv2D(280, 1, kernel_regularizer=l2(l=0.0005)), # 3\n",
    "    Activation(my_activation),\n",
    "    Conv2D(300, 2), # 2\n",
    "    Activation(my_activation),\n",
    "    MaxPooling2D(), # 1\n",
    "    Dropout(0.4),\n",
    "    # Block 6\n",
    "    Conv2D(300, 1, kernel_regularizer=l2(l=0.0005)), # 1\n",
    "    Activation(my_activation),\n",
    "    Dropout(0.5),\n",
    "    # Block 7\n",
    "    Conv2D(10, 1, kernel_regularizer=l2(l=0.0005)), # 1\n",
    "    Activation('sigmoid'),\n",
    "    Flatten()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import top_k_categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(#'adam',\n",
    "              SGD(lr=0.01, momentum=0.9),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', top_k_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/330\n",
      "500/500 [==============================] - 47s 94ms/step - loss: 3.1157 - acc: 0.1917 - top_k_categorical_accuracy: 0.6991 - val_loss: 2.9203 - val_acc: 0.2700 - val_top_k_categorical_accuracy: 0.8104\n",
      "Epoch 2/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 2.8198 - acc: 0.2827 - top_k_categorical_accuracy: 0.8192 - val_loss: 2.6224 - val_acc: 0.3270 - val_top_k_categorical_accuracy: 0.8724\n",
      "Epoch 3/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 2.5985 - acc: 0.3457 - top_k_categorical_accuracy: 0.8574 - val_loss: 2.4535 - val_acc: 0.3750 - val_top_k_categorical_accuracy: 0.8825\n",
      "Epoch 4/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 2.4364 - acc: 0.3871 - top_k_categorical_accuracy: 0.8776 - val_loss: 2.2918 - val_acc: 0.4269 - val_top_k_categorical_accuracy: 0.8985\n",
      "Epoch 5/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 2.2979 - acc: 0.4166 - top_k_categorical_accuracy: 0.8928 - val_loss: 2.1886 - val_acc: 0.4435 - val_top_k_categorical_accuracy: 0.9044\n",
      "Epoch 6/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 2.1916 - acc: 0.4428 - top_k_categorical_accuracy: 0.9017 - val_loss: 2.0461 - val_acc: 0.4850 - val_top_k_categorical_accuracy: 0.9200\n",
      "Epoch 7/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 2.0944 - acc: 0.4609 - top_k_categorical_accuracy: 0.9080 - val_loss: 1.9749 - val_acc: 0.4891 - val_top_k_categorical_accuracy: 0.9268\n",
      "Epoch 8/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 2.0076 - acc: 0.4779 - top_k_categorical_accuracy: 0.9158 - val_loss: 1.8869 - val_acc: 0.5130 - val_top_k_categorical_accuracy: 0.9281\n",
      "Epoch 9/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.9315 - acc: 0.4965 - top_k_categorical_accuracy: 0.9238 - val_loss: 1.8273 - val_acc: 0.5186 - val_top_k_categorical_accuracy: 0.9302\n",
      "Epoch 10/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.8556 - acc: 0.5103 - top_k_categorical_accuracy: 0.9267 - val_loss: 1.7472 - val_acc: 0.5458 - val_top_k_categorical_accuracy: 0.9361\n",
      "Epoch 11/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.7873 - acc: 0.5256 - top_k_categorical_accuracy: 0.9312 - val_loss: 1.6871 - val_acc: 0.5549 - val_top_k_categorical_accuracy: 0.9431\n",
      "Epoch 12/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.7282 - acc: 0.5398 - top_k_categorical_accuracy: 0.9360 - val_loss: 1.6312 - val_acc: 0.5698 - val_top_k_categorical_accuracy: 0.9414\n",
      "Epoch 13/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.6742 - acc: 0.5528 - top_k_categorical_accuracy: 0.9388 - val_loss: 1.5882 - val_acc: 0.5750 - val_top_k_categorical_accuracy: 0.9466\n",
      "Epoch 14/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.6338 - acc: 0.5579 - top_k_categorical_accuracy: 0.9410 - val_loss: 1.5608 - val_acc: 0.5737 - val_top_k_categorical_accuracy: 0.9476\n",
      "Epoch 15/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.5924 - acc: 0.5688 - top_k_categorical_accuracy: 0.9434 - val_loss: 1.5123 - val_acc: 0.5851 - val_top_k_categorical_accuracy: 0.9552\n",
      "Epoch 16/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.5487 - acc: 0.5759 - top_k_categorical_accuracy: 0.9476 - val_loss: 1.4962 - val_acc: 0.5823 - val_top_k_categorical_accuracy: 0.9527\n",
      "Epoch 17/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.5139 - acc: 0.5844 - top_k_categorical_accuracy: 0.9498 - val_loss: 1.4918 - val_acc: 0.5817 - val_top_k_categorical_accuracy: 0.9472\n",
      "Epoch 18/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.4888 - acc: 0.5905 - top_k_categorical_accuracy: 0.9508 - val_loss: 1.4050 - val_acc: 0.6142 - val_top_k_categorical_accuracy: 0.9569\n",
      "Epoch 19/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.4593 - acc: 0.5992 - top_k_categorical_accuracy: 0.9512 - val_loss: 1.3862 - val_acc: 0.6194 - val_top_k_categorical_accuracy: 0.9564\n",
      "Epoch 20/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.4356 - acc: 0.6062 - top_k_categorical_accuracy: 0.9525 - val_loss: 1.3990 - val_acc: 0.6101 - val_top_k_categorical_accuracy: 0.9554\n",
      "Epoch 21/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.4119 - acc: 0.6083 - top_k_categorical_accuracy: 0.9534 - val_loss: 1.3631 - val_acc: 0.6167 - val_top_k_categorical_accuracy: 0.9570\n",
      "Epoch 22/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.3877 - acc: 0.6134 - top_k_categorical_accuracy: 0.9552 - val_loss: 1.3547 - val_acc: 0.6208 - val_top_k_categorical_accuracy: 0.9597\n",
      "Epoch 23/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.3738 - acc: 0.6166 - top_k_categorical_accuracy: 0.9572 - val_loss: 1.3112 - val_acc: 0.6343 - val_top_k_categorical_accuracy: 0.9619\n",
      "Epoch 24/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.3557 - acc: 0.6215 - top_k_categorical_accuracy: 0.9575 - val_loss: 1.3055 - val_acc: 0.6307 - val_top_k_categorical_accuracy: 0.9598\n",
      "Epoch 25/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.3374 - acc: 0.6281 - top_k_categorical_accuracy: 0.9579 - val_loss: 1.2833 - val_acc: 0.6408 - val_top_k_categorical_accuracy: 0.9605\n",
      "Epoch 26/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.3256 - acc: 0.6295 - top_k_categorical_accuracy: 0.9574 - val_loss: 1.2729 - val_acc: 0.6489 - val_top_k_categorical_accuracy: 0.9611\n",
      "Epoch 27/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.3149 - acc: 0.6312 - top_k_categorical_accuracy: 0.9594 - val_loss: 1.2857 - val_acc: 0.6345 - val_top_k_categorical_accuracy: 0.9621\n",
      "Epoch 28/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.3005 - acc: 0.6360 - top_k_categorical_accuracy: 0.9592 - val_loss: 1.2716 - val_acc: 0.6382 - val_top_k_categorical_accuracy: 0.9619\n",
      "Epoch 29/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.2900 - acc: 0.6372 - top_k_categorical_accuracy: 0.9608 - val_loss: 1.2532 - val_acc: 0.6391 - val_top_k_categorical_accuracy: 0.9651\n",
      "Epoch 30/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.2817 - acc: 0.6406 - top_k_categorical_accuracy: 0.9606 - val_loss: 1.2642 - val_acc: 0.6453 - val_top_k_categorical_accuracy: 0.9624\n",
      "Epoch 31/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.2719 - acc: 0.6430 - top_k_categorical_accuracy: 0.9622 - val_loss: 1.2379 - val_acc: 0.6503 - val_top_k_categorical_accuracy: 0.9647\n",
      "Epoch 32/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.2631 - acc: 0.6456 - top_k_categorical_accuracy: 0.9630 - val_loss: 1.2343 - val_acc: 0.6463 - val_top_k_categorical_accuracy: 0.9661\n",
      "Epoch 33/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.2568 - acc: 0.6484 - top_k_categorical_accuracy: 0.9625 - val_loss: 1.2388 - val_acc: 0.6459 - val_top_k_categorical_accuracy: 0.9650\n",
      "Epoch 34/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.2492 - acc: 0.6505 - top_k_categorical_accuracy: 0.9638 - val_loss: 1.2318 - val_acc: 0.6537 - val_top_k_categorical_accuracy: 0.9641\n",
      "Epoch 35/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.2355 - acc: 0.6541 - top_k_categorical_accuracy: 0.9648 - val_loss: 1.2603 - val_acc: 0.6438 - val_top_k_categorical_accuracy: 0.9575\n",
      "Epoch 36/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.2365 - acc: 0.6565 - top_k_categorical_accuracy: 0.9628 - val_loss: 1.2078 - val_acc: 0.6578 - val_top_k_categorical_accuracy: 0.9659\n",
      "Epoch 37/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.2297 - acc: 0.6547 - top_k_categorical_accuracy: 0.9639 - val_loss: 1.2274 - val_acc: 0.6530 - val_top_k_categorical_accuracy: 0.9643\n",
      "Epoch 38/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.2257 - acc: 0.6572 - top_k_categorical_accuracy: 0.9643 - val_loss: 1.2250 - val_acc: 0.6589 - val_top_k_categorical_accuracy: 0.9634\n",
      "Epoch 39/330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 45s 90ms/step - loss: 1.2203 - acc: 0.6620 - top_k_categorical_accuracy: 0.9660 - val_loss: 1.2037 - val_acc: 0.6612 - val_top_k_categorical_accuracy: 0.9656\n",
      "Epoch 40/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.2201 - acc: 0.6593 - top_k_categorical_accuracy: 0.9652 - val_loss: 1.1933 - val_acc: 0.6651 - val_top_k_categorical_accuracy: 0.9673\n",
      "Epoch 41/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.2114 - acc: 0.6593 - top_k_categorical_accuracy: 0.9661 - val_loss: 1.2163 - val_acc: 0.6595 - val_top_k_categorical_accuracy: 0.9627\n",
      "Epoch 42/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.2064 - acc: 0.6644 - top_k_categorical_accuracy: 0.9658 - val_loss: 1.2090 - val_acc: 0.6614 - val_top_k_categorical_accuracy: 0.9644\n",
      "Epoch 43/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1964 - acc: 0.6692 - top_k_categorical_accuracy: 0.9663 - val_loss: 1.2027 - val_acc: 0.6640 - val_top_k_categorical_accuracy: 0.9646\n",
      "Epoch 44/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1964 - acc: 0.6669 - top_k_categorical_accuracy: 0.9667 - val_loss: 1.1751 - val_acc: 0.6759 - val_top_k_categorical_accuracy: 0.9682\n",
      "Epoch 45/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1964 - acc: 0.6690 - top_k_categorical_accuracy: 0.9674 - val_loss: 1.1861 - val_acc: 0.6667 - val_top_k_categorical_accuracy: 0.9660\n",
      "Epoch 46/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1838 - acc: 0.6741 - top_k_categorical_accuracy: 0.9689 - val_loss: 1.1972 - val_acc: 0.6711 - val_top_k_categorical_accuracy: 0.9661\n",
      "Epoch 47/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1936 - acc: 0.6681 - top_k_categorical_accuracy: 0.9672 - val_loss: 1.2176 - val_acc: 0.6618 - val_top_k_categorical_accuracy: 0.9653\n",
      "Epoch 48/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1868 - acc: 0.6700 - top_k_categorical_accuracy: 0.9678 - val_loss: 1.2042 - val_acc: 0.6647 - val_top_k_categorical_accuracy: 0.9671\n",
      "Epoch 49/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1762 - acc: 0.6754 - top_k_categorical_accuracy: 0.9687 - val_loss: 1.1866 - val_acc: 0.6697 - val_top_k_categorical_accuracy: 0.9680\n",
      "Epoch 50/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1785 - acc: 0.6730 - top_k_categorical_accuracy: 0.9686 - val_loss: 1.1984 - val_acc: 0.6618 - val_top_k_categorical_accuracy: 0.9670\n",
      "Epoch 51/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1752 - acc: 0.6764 - top_k_categorical_accuracy: 0.9693 - val_loss: 1.1763 - val_acc: 0.6744 - val_top_k_categorical_accuracy: 0.9675\n",
      "Epoch 52/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1713 - acc: 0.6777 - top_k_categorical_accuracy: 0.9690 - val_loss: 1.1807 - val_acc: 0.6726 - val_top_k_categorical_accuracy: 0.9670\n",
      "Epoch 53/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1723 - acc: 0.6769 - top_k_categorical_accuracy: 0.9694 - val_loss: 1.2055 - val_acc: 0.6608 - val_top_k_categorical_accuracy: 0.9659\n",
      "Epoch 54/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1687 - acc: 0.6778 - top_k_categorical_accuracy: 0.9693 - val_loss: 1.1790 - val_acc: 0.6709 - val_top_k_categorical_accuracy: 0.9678\n",
      "Epoch 55/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1645 - acc: 0.6819 - top_k_categorical_accuracy: 0.9693 - val_loss: 1.1800 - val_acc: 0.6742 - val_top_k_categorical_accuracy: 0.9668\n",
      "Epoch 56/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1585 - acc: 0.6818 - top_k_categorical_accuracy: 0.9696 - val_loss: 1.1718 - val_acc: 0.6741 - val_top_k_categorical_accuracy: 0.9679\n",
      "Epoch 57/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1629 - acc: 0.6812 - top_k_categorical_accuracy: 0.9691 - val_loss: 1.1881 - val_acc: 0.6724 - val_top_k_categorical_accuracy: 0.9677\n",
      "Epoch 58/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1601 - acc: 0.6831 - top_k_categorical_accuracy: 0.9705 - val_loss: 1.1850 - val_acc: 0.6681 - val_top_k_categorical_accuracy: 0.9684\n",
      "Epoch 59/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1607 - acc: 0.6826 - top_k_categorical_accuracy: 0.9697 - val_loss: 1.1770 - val_acc: 0.6754 - val_top_k_categorical_accuracy: 0.9680\n",
      "Epoch 60/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1558 - acc: 0.6817 - top_k_categorical_accuracy: 0.9710 - val_loss: 1.1968 - val_acc: 0.6699 - val_top_k_categorical_accuracy: 0.9661\n",
      "Epoch 61/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1517 - acc: 0.6852 - top_k_categorical_accuracy: 0.9718 - val_loss: 1.1736 - val_acc: 0.6815 - val_top_k_categorical_accuracy: 0.9698\n",
      "Epoch 62/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1555 - acc: 0.6850 - top_k_categorical_accuracy: 0.9707 - val_loss: 1.1708 - val_acc: 0.6846 - val_top_k_categorical_accuracy: 0.9671\n",
      "Epoch 63/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1532 - acc: 0.6860 - top_k_categorical_accuracy: 0.9701 - val_loss: 1.1736 - val_acc: 0.6825 - val_top_k_categorical_accuracy: 0.9671\n",
      "Epoch 64/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1531 - acc: 0.6839 - top_k_categorical_accuracy: 0.9716 - val_loss: 1.2224 - val_acc: 0.6594 - val_top_k_categorical_accuracy: 0.9641\n",
      "Epoch 65/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1469 - acc: 0.6888 - top_k_categorical_accuracy: 0.9708 - val_loss: 1.1672 - val_acc: 0.6800 - val_top_k_categorical_accuracy: 0.9683\n",
      "Epoch 66/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1453 - acc: 0.6901 - top_k_categorical_accuracy: 0.9719 - val_loss: 1.1557 - val_acc: 0.6878 - val_top_k_categorical_accuracy: 0.9712\n",
      "Epoch 67/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1440 - acc: 0.6891 - top_k_categorical_accuracy: 0.9714 - val_loss: 1.1922 - val_acc: 0.6736 - val_top_k_categorical_accuracy: 0.9678\n",
      "Epoch 68/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1449 - acc: 0.6882 - top_k_categorical_accuracy: 0.9725 - val_loss: 1.1597 - val_acc: 0.6851 - val_top_k_categorical_accuracy: 0.9681\n",
      "Epoch 69/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1450 - acc: 0.6890 - top_k_categorical_accuracy: 0.9717 - val_loss: 1.1576 - val_acc: 0.6847 - val_top_k_categorical_accuracy: 0.9705\n",
      "Epoch 70/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.1420 - acc: 0.6931 - top_k_categorical_accuracy: 0.9714 - val_loss: 1.1586 - val_acc: 0.6897 - val_top_k_categorical_accuracy: 0.9671\n",
      "Epoch 71/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0836 - acc: 0.7107 - top_k_categorical_accuracy: 0.9755 - val_loss: 1.1344 - val_acc: 0.6942 - val_top_k_categorical_accuracy: 0.9705\n",
      "Epoch 72/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0618 - acc: 0.7198 - top_k_categorical_accuracy: 0.9771 - val_loss: 1.1202 - val_acc: 0.7011 - val_top_k_categorical_accuracy: 0.9710\n",
      "Epoch 73/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0568 - acc: 0.7218 - top_k_categorical_accuracy: 0.9757 - val_loss: 1.1160 - val_acc: 0.6989 - val_top_k_categorical_accuracy: 0.9738\n",
      "Epoch 74/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0485 - acc: 0.7238 - top_k_categorical_accuracy: 0.9768 - val_loss: 1.1119 - val_acc: 0.7014 - val_top_k_categorical_accuracy: 0.9717\n",
      "Epoch 75/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0480 - acc: 0.7236 - top_k_categorical_accuracy: 0.9772 - val_loss: 1.1136 - val_acc: 0.7014 - val_top_k_categorical_accuracy: 0.9712\n",
      "Epoch 76/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0462 - acc: 0.7226 - top_k_categorical_accuracy: 0.9771 - val_loss: 1.1130 - val_acc: 0.7020 - val_top_k_categorical_accuracy: 0.9721\n",
      "Epoch 77/330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0421 - acc: 0.7267 - top_k_categorical_accuracy: 0.9771 - val_loss: 1.1194 - val_acc: 0.6987 - val_top_k_categorical_accuracy: 0.9723\n",
      "Epoch 78/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0436 - acc: 0.7230 - top_k_categorical_accuracy: 0.9766 - val_loss: 1.1441 - val_acc: 0.6889 - val_top_k_categorical_accuracy: 0.9708\n",
      "Epoch 79/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0411 - acc: 0.7255 - top_k_categorical_accuracy: 0.9770 - val_loss: 1.1090 - val_acc: 0.7025 - val_top_k_categorical_accuracy: 0.9716\n",
      "Epoch 80/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0372 - acc: 0.7261 - top_k_categorical_accuracy: 0.9778 - val_loss: 1.1029 - val_acc: 0.7035 - val_top_k_categorical_accuracy: 0.9733\n",
      "Epoch 81/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0296 - acc: 0.7286 - top_k_categorical_accuracy: 0.9775 - val_loss: 1.1300 - val_acc: 0.6972 - val_top_k_categorical_accuracy: 0.9704\n",
      "Epoch 82/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0342 - acc: 0.7262 - top_k_categorical_accuracy: 0.9776 - val_loss: 1.1142 - val_acc: 0.6961 - val_top_k_categorical_accuracy: 0.9713\n",
      "Epoch 83/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0329 - acc: 0.7278 - top_k_categorical_accuracy: 0.9784 - val_loss: 1.1048 - val_acc: 0.7080 - val_top_k_categorical_accuracy: 0.9727\n",
      "Epoch 84/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0295 - acc: 0.7276 - top_k_categorical_accuracy: 0.9785 - val_loss: 1.1123 - val_acc: 0.7028 - val_top_k_categorical_accuracy: 0.9729\n",
      "Epoch 85/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0291 - acc: 0.7283 - top_k_categorical_accuracy: 0.9776 - val_loss: 1.1016 - val_acc: 0.7039 - val_top_k_categorical_accuracy: 0.9741\n",
      "Epoch 86/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0215 - acc: 0.7315 - top_k_categorical_accuracy: 0.9779 - val_loss: 1.1175 - val_acc: 0.6983 - val_top_k_categorical_accuracy: 0.9724\n",
      "Epoch 87/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0232 - acc: 0.7301 - top_k_categorical_accuracy: 0.9786 - val_loss: 1.1089 - val_acc: 0.7027 - val_top_k_categorical_accuracy: 0.9728\n",
      "Epoch 88/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0237 - acc: 0.7303 - top_k_categorical_accuracy: 0.9791 - val_loss: 1.1179 - val_acc: 0.6983 - val_top_k_categorical_accuracy: 0.9706\n",
      "Epoch 89/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0238 - acc: 0.7288 - top_k_categorical_accuracy: 0.9786 - val_loss: 1.1172 - val_acc: 0.6969 - val_top_k_categorical_accuracy: 0.9729\n",
      "Epoch 90/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0216 - acc: 0.7304 - top_k_categorical_accuracy: 0.9786 - val_loss: 1.1106 - val_acc: 0.6981 - val_top_k_categorical_accuracy: 0.9724\n",
      "Epoch 91/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0180 - acc: 0.7321 - top_k_categorical_accuracy: 0.9786 - val_loss: 1.1213 - val_acc: 0.6941 - val_top_k_categorical_accuracy: 0.9713\n",
      "Epoch 92/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0242 - acc: 0.7268 - top_k_categorical_accuracy: 0.9793 - val_loss: 1.1098 - val_acc: 0.7020 - val_top_k_categorical_accuracy: 0.9716\n",
      "Epoch 93/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0225 - acc: 0.7314 - top_k_categorical_accuracy: 0.9790 - val_loss: 1.1009 - val_acc: 0.7059 - val_top_k_categorical_accuracy: 0.9732\n",
      "Epoch 94/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0173 - acc: 0.7349 - top_k_categorical_accuracy: 0.9797 - val_loss: 1.1079 - val_acc: 0.6988 - val_top_k_categorical_accuracy: 0.9728\n",
      "Epoch 95/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0229 - acc: 0.7316 - top_k_categorical_accuracy: 0.9789 - val_loss: 1.1204 - val_acc: 0.6989 - val_top_k_categorical_accuracy: 0.9709\n",
      "Epoch 96/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0197 - acc: 0.7324 - top_k_categorical_accuracy: 0.9784 - val_loss: 1.1289 - val_acc: 0.6939 - val_top_k_categorical_accuracy: 0.9729\n",
      "Epoch 97/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0163 - acc: 0.7321 - top_k_categorical_accuracy: 0.9803 - val_loss: 1.1056 - val_acc: 0.7021 - val_top_k_categorical_accuracy: 0.9730\n",
      "Epoch 98/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0135 - acc: 0.7337 - top_k_categorical_accuracy: 0.9794 - val_loss: 1.0988 - val_acc: 0.7065 - val_top_k_categorical_accuracy: 0.9730\n",
      "Epoch 99/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0107 - acc: 0.7330 - top_k_categorical_accuracy: 0.9797 - val_loss: 1.1150 - val_acc: 0.7031 - val_top_k_categorical_accuracy: 0.9726\n",
      "Epoch 100/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0122 - acc: 0.7331 - top_k_categorical_accuracy: 0.9795 - val_loss: 1.1031 - val_acc: 0.7091 - val_top_k_categorical_accuracy: 0.9728\n",
      "Epoch 101/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0173 - acc: 0.7321 - top_k_categorical_accuracy: 0.9787 - val_loss: 1.1145 - val_acc: 0.6981 - val_top_k_categorical_accuracy: 0.9740\n",
      "Epoch 102/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0123 - acc: 0.7343 - top_k_categorical_accuracy: 0.9793 - val_loss: 1.0955 - val_acc: 0.7084 - val_top_k_categorical_accuracy: 0.9712\n",
      "Epoch 103/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0098 - acc: 0.7360 - top_k_categorical_accuracy: 0.9798 - val_loss: 1.1130 - val_acc: 0.7002 - val_top_k_categorical_accuracy: 0.9728\n",
      "Epoch 104/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0085 - acc: 0.7357 - top_k_categorical_accuracy: 0.9806 - val_loss: 1.1037 - val_acc: 0.7050 - val_top_k_categorical_accuracy: 0.9713\n",
      "Epoch 105/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0103 - acc: 0.7350 - top_k_categorical_accuracy: 0.9803 - val_loss: 1.1107 - val_acc: 0.7033 - val_top_k_categorical_accuracy: 0.9726\n",
      "Epoch 106/330\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.0126 - acc: 0.7354 - top_k_categorical_accuracy: 0.9800 - val_loss: 1.1067 - val_acc: 0.7022 - val_top_k_categorical_accuracy: 0.9722\n",
      "Epoch 107/330\n",
      "420/500 [========================>.....] - ETA: 6s - loss: 1.0042 - acc: 0.7378 - top_k_categorical_accuracy: 0.9803"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size=100),\n",
    "                           validation_data=[x_test, y_test],\n",
    "                           epochs=330,\n",
    "                           callbacks=[tensorboard, schedule]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
